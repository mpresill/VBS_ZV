{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZV_functions import *\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_dir='/eos/home-a/ahakimi/www/ZV_analysis'\n",
    "base_dir='D:\\\\Travail\\\\ZV_analysis\\\\'\n",
    "year='2018_SR_new'\n",
    "cut='Boosted_SR'\n",
    "vers=''\n",
    "\n",
    "\n",
    "if cut == 'Boosted_SR':\n",
    "    features =['pt1', 'pt2', 'eta1',\n",
    "           'eta2', 'mll',\n",
    "           'FatJet_pt', 'FatJeteta',\n",
    "           'Zlep_1', 'Zlep_2', \n",
    "           'vbs_jet_pt1', 'vbs_jet_pt2',\n",
    "           'vbs_jet_eta1', 'vbs_jet_eta2',\n",
    "           'mjj_max', 'detajj_mjjmax']\n",
    "elif cut == 'Resolved_SR':\n",
    "    features=['pt1', 'pt2', 'eta1',\n",
    "           'eta2', 'mll',\n",
    "           'Zlep_1', 'Zlep_2', \n",
    "           'vbs_jet_pt1', 'vbs_jet_pt2',\n",
    "           'vbs_jet_eta1', 'vbs_jet_eta2',\n",
    "           'V_jet_pt1', 'V_jet_pt2',\n",
    "           'V_jet_eta1', 'V_jet_eta2',\n",
    "           'mjj_max', 'detajj_mjjmax',\n",
    "           'V_jet_mass']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y, variables_list=prep_data(year, cut, vers, base_dir) #\n",
    "\n",
    "xlims=[(0,200),(0,150),(-3,3),(-3,3),(0,150),(0,5),(0,10),(0,900),(-5,5),(0,200),(0,1),(-1.5,1.5),(-1.5,1.5),(-1,1),\n",
    "       (0,200),(0,200),(-5,5),(-5,5),\n",
    "           (0,200),(0,100),(-5,5),(-5,5),(0,3000),(0,10),(0,4),(0,150)]\n",
    "\n",
    "#plot_distrib(variables_list, xlims,base_dir, year, cut)\n",
    "print('NUmber of events: {}, signal : {}, bkg: {}'.format(len(y),len(y[y['signal']==1]),len(y[y['signal']==0])))\n",
    "print('SOW: {}, signal : {}, bkg: {}'.format(sum(y['weight_']),sum(y['weight_'][y['signal']==1]),sum(y['weight_'][y['signal']==0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=base_dir+year+'\\\\'+cut+'\\\\data'+vers\n",
    "\n",
    "res_dir=base_dir+year+'\\\\'+cut+'\\\\BDT_res'+vers\n",
    "\n",
    "input_list= features\n",
    "inputs= [cut+'_'+i for i in input_list]\n",
    "\n",
    "if not os.path.exists(res_dir):\n",
    "        os.makedirs(res_dir)\n",
    "\n",
    "X= pd.DataFrame(np.load(data_dir+'\\\\X_{}_{}{}.npy'.format(year,cut,vers), allow_pickle=True), columns=variables_list)\n",
    "X=X[inputs]\n",
    "y= pd.DataFrame(np.load(data_dir+'\\\\y_{}_{}{}.npy'.format(year,cut,vers), allow_pickle=True), columns= ['signal','sample','group','weight_', 'w'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=42)\n",
    "\n",
    "\n",
    "dtrain=xgb.DMatrix(data=X_train,label=y_train['signal'], feature_names=features_Resolved, weight=y_train['w'])\n",
    "dtest=xgb.DMatrix(data=X_test,label=y_test['signal'], feature_names=features_Resolved, weight=y_test['w'])\n",
    "param = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':4,\n",
    "    'min_child_weight': sum(y['w'])/len(y),\n",
    "    'eta':0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    # Other parameters\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric': 'auc', \n",
    "}\n",
    "\n",
    "#use gpu if available\n",
    "gpu=tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "if gpu==True:\n",
    "    param['tree_method']='gpu_hist'\n",
    "    \n",
    "\n",
    "num_boost_round=400\n",
    "es_rounds=10\n",
    "#watchlist=\n",
    "progress={}\n",
    "\n",
    "metrics={'logloss','auc'} #last one used for es\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# grid search:\n",
    "gridsearch_params = [\n",
    "    (max_depth, eta, l1, l2)\n",
    "    for max_depth in [4,5,6,8,10]\n",
    "    for eta in [0.01,0.05,0.1,0.2,0.3]\n",
    "    for l1 in [0.01, 0.1,1,10] #alpha, def= 0\n",
    "    for l2 in [0.01, 0.1,1,10] #lambda, def=1\n",
    "]\n",
    "tot_iter=len(gridsearch_params)\n",
    "n_iter=0\n",
    "max_score = 0\n",
    "best_params = None\n",
    "for max_depth, eta, l1, l2 in gridsearch_params:\n",
    "    n_iter+=1\n",
    "    print(\"CV {}/{} with max_depth={}, eta={}, l1={}, l2={}\".format(n_iter, tot_iter,\n",
    "                             max_depth, eta, l1, l2))\n",
    "    # Update our parameters\n",
    "    param['max_depth'] = max_depth\n",
    "    param['eta'] = eta\n",
    "    param['alpha']= l1\n",
    "    param['lambda']=l2\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'auc'},\n",
    "        early_stopping_rounds=es_rounds\n",
    "    )\n",
    "    # Update best MAE\n",
    "    alpha=1\n",
    "    mean_score = (cv_results['test-auc-mean']-alpha*abs(cv_results['test-auc-mean']-cv_results['train-auc-mean'])).max()\n",
    "    boost_rounds = (cv_results['test-auc-mean']-alpha*abs(cv_results['test-auc-mean']-cv_results['train-auc-mean'])).argmax()\n",
    "    print(\"\\tScore {} in {} rounds\".format(mean_score, boost_rounds))\n",
    "    if mean_score > max_score:\n",
    "        max_score = mean_score\n",
    "        best_params = (max_depth,eta, l1, l2)\n",
    "print(\"Best params: {},  Score: {}\".format(best_params, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
