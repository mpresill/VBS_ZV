{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZV_functions import *\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_dir='/eos/home-a/ahakimi/www/ZV_analysis'\n",
    "base_dir='D:\\\\Travail\\\\ZV_analysis\\\\'\n",
    "year='2018_SR_new'\n",
    "cut='Boosted_SR'\n",
    "vers=''\n",
    "\n",
    "variables_list= ['Resolved_SR_pt1', 'Resolved_SR_pt2', 'Resolved_SR_eta1',\n",
    "       'Resolved_SR_eta2', 'Resolved_SR_mll', 'Resolved_SR_Zepp_ll',\n",
    "       'Resolved_SR_nFatJet', 'Resolved_SR_FatJet_pt', 'Resolved_SR_FatJeteta',\n",
    "       'Resolved_SR_FatJet_softdropmass', 'Resolved_SR_FatJet_tau21',\n",
    "       'Resolved_SR_Zlep_1', 'Resolved_SR_Zlep_2', 'Resolved_SR_category',\n",
    "       'Resolved_SR_vbs_jet_pt1', 'Resolved_SR_vbs_jet_pt2',\n",
    "       'Resolved_SR_vbs_jet_eta1', 'Resolved_SR_vbs_jet_eta2',\n",
    "       'Resolved_SR_V_jet_pt1', 'Resolved_SR_V_jet_pt2',\n",
    "       'Resolved_SR_V_jet_eta1', 'Resolved_SR_V_jet_eta2',\n",
    "       'Resolved_SR_mjj_max', 'Resolved_SR_detajj_mjjmax',\n",
    "       'Resolved_SR_dphijj_mjjmax', 'Resolved_SR_V_jet_mass']\n",
    "if cut == 'Boosted_SR':\n",
    "    features =['pt1', 'pt2', 'eta1',\n",
    "           'eta2', 'mll',\n",
    "           'FatJet_pt', 'FatJeteta',\n",
    "           'Zlep_1', 'Zlep_2', \n",
    "           'vbs_jet_pt1', 'vbs_jet_pt2',\n",
    "           'vbs_jet_eta1', 'vbs_jet_eta2',\n",
    "           'mjj_max', 'detajj_mjjmax']\n",
    "elif cut == 'Resolved_SR'\n",
    "    features=['pt1', 'pt2', 'eta1',\n",
    "           'eta2', 'mll',\n",
    "           'Zlep_1', 'Zlep_2', \n",
    "           'vbs_jet_pt1', 'vbs_jet_pt2',\n",
    "           'vbs_jet_eta1', 'vbs_jet_eta2',\n",
    "           'V_jet_pt1', 'V_jet_pt2',\n",
    "           'V_jet_eta1', 'V_jet_eta2',\n",
    "           'mjj_max', 'detajj_mjjmax',\n",
    "           'V_jet_mass']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir=base_dir+year+'\\\\'+cut+'\\\\data'+vers\n",
    "\n",
    "\n",
    "input_list= features\n",
    "inputs= [cut+'_'+i for i in input_list]\n",
    "\n",
    "\n",
    "\n",
    "X= pd.DataFrame(np.load(data_dir+'\\\\X_{}_{}{}.npy'.format(year,cut,vers), allow_pickle=True), columns=variables_list)\n",
    "X=X[inputs]\n",
    "y= pd.DataFrame(np.load(data_dir+'\\\\y_{}_{}{}.npy'.format(year,cut,vers), allow_pickle=True), columns= ['signal','sample','group','weight_', 'w'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=42)\n",
    "\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=12, inter_op_parallelism_threads=12)\n",
    "tf.set_random_seed(1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "k.tensorflow_backend.set_session(sess)\n",
    "\n",
    "early_stop=5  #number of epochs without gain before stoping\n",
    "predictions_NN={}\n",
    "target={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y, variables_list=prep_data(year, cut, vers, base_dir) #\n",
    "\n",
    "xlims=[(0,200),(0,150),(-3,3),(-3,3),(0,150),(0,5),(0,10),(0,900),(-5,5),(0,200),(0,1),(-1.5,1.5),(-1.5,1.5),(-1,1),\n",
    "       (0,200),(0,200),(-5,5),(-5,5),\n",
    "           (0,200),(0,100),(-5,5),(-5,5),(0,3000),(0,10),(0,4),(0,150)]\n",
    "\n",
    "#plot_distrib(variables_list, xlims,base_dir, year, cut)\n",
    "print('NUmber of events: {}, signal : {}, bkg: {}'.format(len(y),len(y[y['signal']==1]),len(y[y['signal']==0])))\n",
    "print('SOW: {}, signal : {}, bkg: {}'.format(sum(y['weight_']),sum(y['weight_'][y['signal']==1]),sum(y['weight_'][y['signal']==0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn(base_dir, lr, l1, l2, dropout, sl1, sl2, sl3, sl4, sl5):\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "    SoB_thr=0.8\n",
    "   \n",
    "    \n",
    "    NN_name='DNN_{}_{}_{}_{}_{}_lr{}_dp{}'.format(sl1,sl2,sl3,sl4,sl5,lr,dropout)\n",
    "    reg=regularizers.L1L2(l1,l2)\n",
    "    opt=Adam(lr=lr)\n",
    "    #opt=SGD(lr=lr, momentum=0.99)\n",
    "\n",
    "\n",
    "    DNN=Sequential()\n",
    "    act_func=tfunc\n",
    "    #,kernel_constraint=maxnorm(3)\n",
    "    DNN.add(Dense(sl1,input_dim=len(inputs),activation=act_func,kernel_regularizer=reg))\n",
    "    DNN.add(BatchNormalization())\n",
    "    DNN.add(Dropout(rate=dropout))\n",
    "    \n",
    "\n",
    "    if sl2!=0:\n",
    "        DNN.add(Dense(sl2,activation=act_func,kernel_regularizer=reg))\n",
    "        DNN.add(BatchNormalization())\n",
    "        DNN.add(Dropout(rate=dropout))\n",
    "        \n",
    "    if sl3!=0:\n",
    "        DNN.add(Dense(sl3,activation=act_func,kernel_regularizer=reg))\n",
    "        DNN.add(BatchNormalization())\n",
    "        DNN.add(Dropout(rate=dropout))\n",
    "        \n",
    "    if sl4!=0:\n",
    "        DNN.add(Dense(sl4,activation=act_func))\n",
    "        DNN.add(BatchNormalization())\n",
    "        DNN.add(Dropout(rate=dropout))\n",
    "        \n",
    "    if sl5!=0:\n",
    "        DNN.add(Dense(sl5,activation=act_func))\n",
    "        DNN.add(BatchNormalization())\n",
    "        DNN.add(Dropout(rate=dropout))\n",
    "        \n",
    "\n",
    "\n",
    "    DNN.add(Dense(1,activation='sigmoid'))\n",
    "    #DNN.add(BatchNormalization())\n",
    "    #tp= tf.keras.metrics.TruePositives(thresholds =SoB_thr, name= 'tp')\n",
    "    #fp= tf.keras.metrics.FalsePositives(thresholds =SoB_thr, name= 'fp')\n",
    "    auc=tf.keras.metrics.AUC()\n",
    "    DNN.compile(loss=loss,optimizer=opt ) #, metrics=[ auc]'auc [ auc, tp, fp]\n",
    "    \n",
    "    return DNN, NN_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes_opt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "import keras.backend as k\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "def Score(roc_auc, roc_auc_train):\n",
    "    alpha=1\n",
    "    return roc_auc-alpha*(np.abs(roc_auc-roc_auc_train))\n",
    "    #function to optimize in optimization\n",
    "    \n",
    "def Score_dnn(n_layer, size_layer, lr):\n",
    "    lr=lr\n",
    "    l1=0\n",
    "    l2=0.001\n",
    "    dropout=0.2\n",
    "    n_layer=int(n_layer)\n",
    "    size_layer=int(size_layer)\n",
    "    sl1=size_layer\n",
    "    sl2,sl3,sl4,sl5 = 0,0,0,0\n",
    "    if n_layer >= 2:\n",
    "        sl2=size_layer\n",
    "    if n_layer >= 3:\n",
    "        sl3=size_layer\n",
    "    if n_layer >= 4:\n",
    "        sl4=size_layer\n",
    "    if n_layer >= 5:\n",
    "        sl5=size_layer\n",
    "    \n",
    "    base_dir='D:\\\\Travail\\\\ZV_analysis\\\\'\n",
    "    print('training network with [{}_{}_{}_{}_{}] neurons'.format(sl1,sl2,sl3,sl4,sl5))\n",
    "    DNN, res_dir=build_dnn(base_dir, lr, l1, l2, dropout, sl1, sl2, sl3, sl4, sl5)\n",
    "    \n",
    "    es_callback = EarlyStopping(monitor='val_loss', patience=early_stop, restore_best_weights=True)\n",
    "    history=DNN.fit(x=X_train, y=y_train['signal'].to_numpy(),\n",
    "                    sample_weight=y_train['w'].to_numpy(), epochs=epochs, batch_size=batchsize, \n",
    "                    verbose=0, callbacks=[es_callback], \n",
    "                    validation_data=(X_test, y_test['signal'].to_numpy(),y_test['w'].to_numpy()))\n",
    "\n",
    "    test_loss, test_acc = DNN.evaluate(X_test, y_test['signal'], verbose=0)\n",
    "    #test = DNN.evaluate(X_test, y_test['signal'], verbose=0)\n",
    "    #print(test)\n",
    "    #print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "    predictions_NN= DNN.predict(X_test)\n",
    "    predictions_NN_train=DNN.predict(X_train)\n",
    "    fpr, tpr, threshold = roc_curve(y_test['signal'].astype('int32'),predictions_NN, pos_label=1, sample_weight=y_test['w'])\n",
    "    tpr.sort()\n",
    "    fpr.sort()\n",
    "    roc_auc =auc(fpr, tpr)\n",
    "    fpr, tpr, threshold = roc_curve(y_train['signal'].astype('int32'),predictions_NN_train, pos_label=1, sample_weight=y_train['w'])\n",
    "    tpr.sort()\n",
    "    fpr.sort()\n",
    "    roc_auc_train =auc(fpr, tpr)\n",
    "    return Score(roc_auc, roc_auc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize lr, l1,l2, dropout, sls\n",
    "\n",
    "epochs=200\n",
    "batchsize=256\n",
    "tfunc='relu'\n",
    "loss='binary_crossentropy'\n",
    "\n",
    "pbounds={'n_layer': (1, 5),\n",
    "         'size_layer': (20, 300),\n",
    "         'lr':(1e-5, 1e-2),\n",
    "\n",
    "      \n",
    "        }\n",
    "\n",
    "optimizer = bayes_opt.BayesianOptimization(\n",
    "    f=Score_dnn,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=25, n_iter=40)\n",
    "optimizer.max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
